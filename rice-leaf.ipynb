{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow==2.9.1\n!pip install seaborn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-13T04:52:40.350278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import system libs\nimport os\nimport time\nimport shutil\nimport pathlib\nimport itertools\n\n# import data handling tools\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\nfrom tensorflow.keras import regularizers\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint ('modules loaded')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate data paths with labels\ndata_dir = '/kaggle/input/riceleafs/RiceLeafs/train'\nfilepaths = []\nlabels = []\n\nfolds = os.listdir(data_dir)\nfor fold in folds:\n    foldpath = os.path.join(data_dir, fold)\n    filelist = os.listdir(foldpath)\n    for file in filelist:\n        fpath = os.path.join(foldpath, file)\n        filepaths.append(fpath)\n        labels.append(fold)\n\n# Concatenate data paths with labels into one dataframe\nFseries = pd.Series(filepaths, name= 'filepaths')\nLseries = pd.Series(labels, name='labels')\ndf = pd.concat([Fseries, Lseries], axis= 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train dataframe\ntrain_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 123)\n\n# valid and test dataframe\nvalid_df, test_df = train_test_split(dummy_df,  train_size= 0.6, shuffle= True, random_state= 123)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# crobed image size\nbatch_size = 16\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\n\n# Recommended : use custom function for test data batch size, else we can use normal batch size.\nts_length = len(test_df)\ntest_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\ntest_steps = ts_length // test_batch_size\n\n# This function which will be used in image data generator for data augmentation, it just take the image and return it again.\ndef scalar(img):\n    return img\n\ntr_gen = ImageDataGenerator(preprocessing_function= scalar)\nts_gen = ImageDataGenerator(preprocessing_function= scalar)\n\ntrain_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n\nvalid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n\n# Note: we will use custom test_batch_size, and make shuffle= false\ntest_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= False, batch_size= test_batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g_dict = train_gen.class_indices      # defines dictionary {'class': index}\nclasses = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\nimages, labels = next(train_gen)      # get a batch size samples from the generator\n\nplt.figure(figsize= (20, 20))\n\nfor i in range(16):\n    plt.subplot(4, 4, i + 1)\n    image = images[i] / 255       # scales data to range (0 - 255)\n    plt.imshow(image)\n    index = np.argmax(labels[i])  # get image index\n    class_name = classes[index]   # get class of image\n    plt.title(class_name, color= 'blue', fontsize= 12)\n    plt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Model Structure\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\nclass_count = len(list(train_gen.class_indices.keys())) # to define number of classes in dense layer\n\n# create pre-trained model (you can built on pretrained model such as :  efficientnet, VGG , Resnet )\n# we will use efficientnetb3 from EfficientNet family.\nbase_model = tf.keras.applications.efficientnet.EfficientNetB0(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n# base_model.trainable = False\n\nmodel = Sequential([\n    base_model,\n    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n    Dense(256, kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n    Dropout(rate= 0.45, seed= 123),\n    Dense(class_count, activation= 'softmax')\n])\n\nmodel.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 16   # set batch size for training\nepochs = 10   # number of all epochs in training\n\nhistory = model.fit(x= train_gen, epochs= epochs, verbose= 1, validation_data= valid_gen, \n                    validation_steps= None, shuffle= False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define needed variables\ntr_acc = history.history['accuracy']\ntr_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n\n# Plot training history\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\n\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts_length = len(test_df)\ntest_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\ntest_steps = ts_length // test_batch_size\n\ntrain_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\nvalid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\ntest_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n\nprint(\"Train Loss: \", train_score[0])\nprint(\"Train Accuracy: \", train_score[1])\nprint('-' * 20)\nprint(\"Validation Loss: \", valid_score[0])\nprint(\"Validation Accuracy: \", valid_score[1])\nprint('-' * 20)\nprint(\"Test Loss: \", test_score[0])\nprint(\"Test Accuracy: \", test_score[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict_generator(test_gen)\ny_pred = np.argmax(preds, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g_dict = test_gen.class_indices\nclasses = list(g_dict.keys())\n\n# Confusion matrix\ncm = confusion_matrix(test_gen.classes, y_pred)\n\nplt.figure(figsize= (10, 10))\nplt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation= 45)\nplt.yticks(tick_marks, classes)\n\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n\nplt.tight_layout()\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report\nprint(classification_report(test_gen.classes, y_pred, target_names= classes))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = model.input_names[0][:-6]\nsubject = 'Mango Diseases'\nacc = test_score[1] * 100\nsave_path = ''\n\n# Save model\nsave_id = str(f'{model_name}-{subject}-{\"%.2f\" %round(acc, 2)}.h5')\nmodel_save_loc = os.path.join(save_path, save_id)\nmodel.save(model_save_loc)\nprint(f'model was saved as {model_save_loc}')\n\n# Save weights\nweight_save_id = str(f'{model_name}-{subject}-weights.h5')\nweights_save_loc = os.path.join(save_path, weight_save_id)\nmodel.save_weights(weights_save_loc)\nprint(f'weights were saved as {weights_save_loc}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}